---
---
= Clustered Cache
ifndef::sourcedir31[]
include::common.adoc[]
endif::sourcedir31[]

ifdef::notBuildingForSite[]
include::menu.adoc[]
endif::notBuildingForSite[]

== Introduction

Distributed Caching allows users to harness additional benefits of horizontal scale-out, without losing on low latency offered by local on-heap tiers.

image::ClusteredEhcacheTopology.png[]

To enable Clustering with Terracotta, you will have to start the http://terracotta.org[Terracotta server] configured with clustered storage.  For convenience, the downloadable Ehcache kit contains the Terracotta Server.

You will then need a configure a cache manager to have clustering capabilities such that the caches it manages can utilize the clustered storage. Finally, any caches which should be distributed should be configured with a clustered storage tier.

== Clustering concepts

In this section we discuss some Terracotta clustering terms and concepts that users need to understand before creating cache managers and caches with clustering support.

Server off-heap resource::
Server off-heap resources are storage resources defined at the server.
Caches can get the storage for their clustered tiers allocated from these server off-heap resources.

Ehcache clustered entity::
_Ehcache clustered entity_ is the server side entity that gives clustering capabilities to a cache manager.
Cache managers connect to such entities to get access to the server's storage resources so that the clustered tiers of caches defined in them can consume those resources.
An Ehcache entity at the server side is identified by a unique _entity identifier_.
Multiple cache managers can identify and connect to the same clustered entity using this unique identifier.

Fixed pool::
Fixed pools are fixed-amount storage pools allocated to the clustered tiers of caches.
A fixed amount of storage is allocated directly from server off-heap resources to these pools.
Caches will have exclusive access to the storage resources in the fixed pool that their clustered tiers are configured with.

Shared pool::
Shared pools are again fixed-amount storage pools, but can be shared by the clustered tiers of multiple caches.
As in the case of fixed pools, shared pools are also carved out from server off-heap resources.
The storage available in these shared pools are strictly shared.
That is, no cache can ask for a fixed amount of storage from these shared pools for its clustered tier.
If a cache needs a fixed amount of storage for its clustered tier that it is not willing to share, then it must get a fixed pool allocated.

Sharing of storage using shared pools here doesn't mean that the data is shared.
That is, if two caches are using a shared pool as their clustered tier, the data of each cache is still isolated but the underlying storage is shared.
What it means is that, when the clustered tier contents of these caches combined, hit the capacity of their shared resource pool,
and when one tries to expand, it could expand by shrinking others' storage resource by evicting its entries if required.

Here is a pictorial representation of the concepts explained above:

image::storagePools.png[]

[[start-server]]
== Starting Terracotta server

You can start the server with the following configuration.
It has the bare minimum configuration required for the samples in the rest of the document to work.
Detailed instructions on how to configure and start a Terracotta server array can be found elsewhere.

[source,xml]
----
include::{sourcedir31}/clustered/client/src/test/resources/configs/docs/tc-config.xml[]
----

The above configuration defines two named _server off-heap resources_:

<1> An off-heap resource of 128 MB size named `primary-server-resource`.
<2> Another off-heap resource named `secondary-server-resource` with 96 MB capacity.

Caches can consume storage from these named resources by configuring their cache manager accordingly.
The rest of the document explains in detail how you can configure cache managers and caches to consume the server's off-heap resources.

Assuming that you have the clustered EhCache kit available locally, start with extracting the *ehcache-clustered* kit.
Change to your extracted directory and then execute the *start-tc-server* script as below to start the Terracotta server with the above configuration:

On Windows:
[source,cmd]
----
cd <path/to/terracotta/kit>/server/bin
start-tc-server.bat -f <path/to/server/config>/tc-config.xml
----

On Unix/Mac:
[source,bash]
----
cd terracotta-5.x.y-SNAPSHOT/server/bin
./start-tc-server.sh -f <path/to/server/config>/tc-config.xml
----

NOTE: You will need to have `JAVA_HOME` set to JDK8 while starting the Terracotta server.

Check for the below `INFO` log to confirm if the server started successfully,
`Terracotta Server instance has started up as ACTIVE node on 0:0:0:0:0:0:0:0:9510 successfully, and is now ready for work.`

== Creating cache manager with clustering capabilities

After <<start-server, starting the Terracotta server>>, you can now proceed to create the cache manager.
For creating the cache manager with clustering support you will need to provide the clustering service configuration.
Here is a code sample that shows how to configure a cache manager with clustering service.

[source,java,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/java/org/ehcache/clustered/client/docs/GettingStarted.java[tag=clusteredCacheManagerExample]
----

<1> Returns the `org.ehcache.config.builders.CacheManagerBuilder` instance;
<2> Use the `ClusteringServiceConfigurationBuilder`{empty}'s static method `.cluster(URI)` for connecting the cache manager to the clustered storage at the
    URI specified that returns the clustering service configuration builder instance.
    Sample URI provided in the example is pointing to the clustered storage instance named `my-application` on the Terracotta server (Assuming the server is running on localhost and port *9510*).
<3> Auto-create the clustered storage if it doesn't already exist.
<4> Returns a fully initialized cache manager that can be used to create clustered caches.
<5> Close the cache manager.

== Cache manager configuration and usage of server side resources

This code sample demonstrates the usage of the concepts explained in the previous section in configuring a cache manager and clustered caches by using a broader clustering service configuration:

[source,java,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/java/org/ehcache/clustered/client/docs/GettingStarted.java[tag=clusteredCacheManagerWithServerSideConfigExample]
----

<1> `defaultServerResource(String)` on `ClusteringServiceConfigurationBuilder` instance sets the default server off-heap resource for the cache manager.
    From the example, cache manager sets its default server off-heap resource to `primary-server-resource` in the server.
<2> Adds a resource pool for the cache manager with the specified name (`resource-pool-a`) and size (`28MB`) consumed out of the named server off-heap resource `secondary-server-resource`.
    A resource pool at the cache manager level maps directly to a shared pool at the server side.
<3> Adds another resource pool for the cache manager with the specified name (`resource-pool-b`) and size (`32MB`).
    Since the server resource identifier is not explicitly passed, this resource pool will be consumed out of default server resource provided in Step 3.
    This demonstrates that a cache manager with clustering support can have multiple resource pools created out of several server off-heap resources.
<4> Provide the cache configuration to be created.
<5> `ClusteredResourcePoolBuilder.fixed(String , long , MemoryUnit)` allocates a fixed pool of storage to the cache from the specified server off-heap resource.
    In this example, a fixed pool of 32MB is allocated for `clustered-cache` from `primary-server-resource`.
<6> `ClusteredResourcePoolBuilder.shared(String)`, passing the name of the resource pool specifies that `shared-cache-1` shares the storage resources with other caches using the same resource pool (`resource-pool-a`).
<7> Configures another cache (`shared-cache-2`) that shares the resource pool (`resource-pool-a`) with `shared-cache-1`.
<8> Creates fully initialized cache manager with the clustered caches.

== Clustered caches


=== Clustered Storage Tier

[source,java,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/java/org/ehcache/clustered/client/docs/GettingStarted.java[tag=clusteredCacheTieredExample]
----

<1> Configuring heap tier for cache.
<2> Configuring clustered tier of fixed size from server off-heap resource using `ClusteredResourcePoolBuilder`.

The equivalent XML configuration is as follows:

[source,xml,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/resources/configs/docs/ehcache-clustered.xml[tag=tieringSample]
----

<1> Specify the heap tier for cache.
<2> Specify the clustered tier for cache through a custom service configuration from the `clustered` namespace.

=== Specifying consistency level

Ehcache offers two level of consistency:

Eventual::
This consistency level indicates that the visibility of a write operation is not guaranteed when the operation returns.
Other clients may still see a stale value for the given key.
However this consistency level guarantees that for a mapping `(K, V1)` updated to `(K, V2)`, once a client sees `(K, V2)` it will never see `(K, V1)` again.
Strong::
This consistency level provides strong visibility guarantees ensuring that when a write operation returns other clients will be able to observe it immediately.
This comes with a latency penalty on the write operation required to give this guarantee.


[source,java,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/java/org/ehcache/clustered/client/docs/GettingStarted.java[tag=clusteredCacheConsistency]
----

<1> Specify the consistency level through the use of additional service configuration, using _strong_ consistency here,
<2> With the consistency used above, this `put` operation will return only when all other clients have had the corresponding mapping invalidated.

The equivalent XML configuration is as follows:

[source,xml,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/resources/configs/docs/ehcache-clustered.xml[tag=consistencySample]
----

<1> Specify the consistency level through a custom service configuration from the `clustered` namespace.

=== Clustered Cache Expiry

Expiry in clustered caches work with an exception that `Expiry#getExpiryForAccess` is handled on a best effort basis for clustered tiers,
it may not be as accurate as in the case of local tiers. Though the same is honored accurately in on-heap tiers.

== Ehcache Clustered Entity Lifecycle

When configuring a cache manager to connect to a clustered entity there are three possible connection modes:
[source,java,indent=0]
----
include::{sourcedir31}/clustered/client/src/test/java/org/ehcache/clustered/client/docs/GettingStarted.java[tag=clusteredCacheManagerLifecycle]
----
<1> In auto-create mode if no entity exists then one is created with the supplied configuration.
If an entity exists and its configuration matches the supplied configuration then a connection is established.
If the supplied configuration does not match then the cache manager will fail to initialize.
<2> In expected mode if an entity exists and its configuration matches the supplied configuration then a connection is established.
If the supplied configuration does not match or the entity does not exist then the cache manager will fail to initialize.
<3> In config-less mode if an entity exists then a connection is established without regard to the configuration of that entity.
If the entity does not exist then the cache manager will fail to initialize.
